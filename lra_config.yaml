listops:
  pe_type: "rpe" # "nope", "spe", "ape", or "rpe"
  vocab_size: 17 # 15 tokens + 1 PAD + 1 CLS
  embed_dim: 32
  max_seq_len: 2000
  enable_kpm: true
  enable_kploss: true
  kernel_type: "none" # 'none', 'dirichlet', 'fejer', 'jackson', 'lanczos', 'lorentz', 'vekic', or 'wang'
  max_order: 2
  mu: 3
  xi: 4.0
  stigma: 0.5
  heta: 2
  dataset: "listops"
  pooling_type: "CLS" # "CLS", "MEAN", "SUM", or "FLATTEN"
  encoder_dim: 32
  mlp_dim: 32
  num_class: 10
  interaction: "None"
  enable_cuda: true
  device_id: 0
  embed_drop_prob: 0.1
  eigenvalue_drop_prob: 0.0
  value_drop_prob: 0.1
  bffn_drop_prob: 0.1
  batch_size: 64
  lr: 0.001
  weight_decay: 0.001
  eta: 0.1
  epochs: 100
  optimizer: "nadamw" # "adamw", "nadamw", "adan", "lion", or "sophia"
  patience: 4
  num_workers: 2

text:
  pe_type: "rpe" # "nope", "spe", "ape", or "rpe"
  vocab_size: 97 # 95 unique symbols + 1 PAD + 1 CLS
  embed_dim: 64
  max_seq_len: 4097
  enable_kpm: true
  enable_kploss: false
  kernel_type: "none" # 'none', 'dirichlet', 'fejer', 'jackson', 'lanczos', 'lorentz', 'vekic', or 'wang'
  max_order: 2
  mu: 3
  xi: 4.0
  stigma: 0.5
  heta: 2
  dataset: "text"
  pooling_type: "CLS" # "CLS", "MEAN", "SUM", or "FLATTEN"
  encoder_dim: 64
  mlp_dim: 64
  num_class: 2
  interaction: "None"
  enable_cuda: true
  device_id: 0
  embed_drop_prob: 0.1
  eigenvalue_drop_prob: 0.0
  value_drop_prob: 0.1
  bffn_drop_prob: 0.1
  batch_size: 32
  lr: 0.001
  weight_decay: 0.001
  eta: 0.001
  epochs: 60
  optimizer: "nadamw" # "adamw", "nadamw", "adan", "lion", or "sophia"
  patience: 4
  num_workers: 2

image:
  pe_type: "rpe" # "nope", "spe", "ape", or "rpe"
  vocab_size: 256 # 256 unique pixel values
  embed_dim: 64
  max_seq_len: 1024
  enable_kpm: true
  enable_kploss: true
  kernel_type: "none" # 'none', 'dirichlet', 'fejer', 'jackson', 'lanczos', 'lorentz', 'vekic', or 'wang'
  max_order: 2
  mu: 3
  xi: 4.0
  stigma: 0.5
  heta: 2
  dataset: "image"
  pooling_type: "FLATTEN" # "CLS", "MEAN", "SUM", or "FLATTEN"
  encoder_dim: 64
  mlp_dim: 64
  num_class: 10
  interaction: "None"
  enable_cuda: true
  device_id: 0 # single GPU
  embed_drop_prob: 0.1
  eigenvalue_drop_prob: 0.0
  value_drop_prob: 0.1
  bffn_drop_prob: 0.1
  batch_size: 64
  lr: 0.001
  weight_decay: 0.001
  eta: 0.1
  epochs: 30
  optimizer: "nadamw" # "adamw", "nadamw", "adan", "lion", or "sophia"
  patience: 1
  num_workers: 2

pathfinder:
  pe_type: "rpe" # "nope", "spe", "ape", or "rpe"
  vocab_size: 225 # 225 unique pixel values
  embed_dim: 64
  max_seq_len: 1024
  enable_kpm: true
  enable_kploss: true
  kernel_type: "none" # 'none', 'dirichlet', 'fejer', 'jackson', 'lanczos', 'lorentz', 'vekic', or 'wang'
  max_order: 2
  mu: 3
  xi: 4.0
  stigma: 0.5
  heta: 2
  dataset: "pathfinder"
  pooling_type: "FLATTEN" # "CLS", "MEAN", "SUM", or "FLATTEN"
  encoder_dim: 64
  mlp_dim: 64
  num_class: 2
  interaction: "None"
  enable_cuda: true
  device_id: 0
  embed_drop_prob: 0.1
  eigenvalue_drop_prob: 0.0
  value_drop_prob: 0.1
  bffn_drop_prob: 0.1
  batch_size: 128
  lr: 0.001
  weight_decay: 0.001
  eta: 0.01
  epochs: 60
  optimizer: "nadamw" # "adamw", "nadamw", "adan", "lion", or "sophia"
  patience: 2
  num_workers: 2

retrieval:
  pe_type: "rpe" # "nope", "spe", "ape", or "rpe"
  vocab_size: 98 # 96 unique symbols + 1 PAD + 1 CLS
  embed_dim: 64
  max_seq_len: 4001
  enable_kpm: true
  enable_kploss: false
  kernel_type: "none" # 'none', 'dirichlet', 'fejer', 'jackson', 'lanczos', 'lorentz', 'vekic', or 'wang'
  max_order: 2
  mu: 3
  xi: 4.0
  stigma: 0.5
  heta: 2
  dataset: "retrieval"
  pooling_type: "CLS" # "CLS", "MEAN", "SUM", or "FLATTEN"
  encoder_dim: 64
  mlp_dim: 64
  num_class: 2
  interaction: "NLI" # "NLI" or "CAT"
  enable_cuda: true
  device_id: 0
  embed_drop_prob: 0.1
  eigenvalue_drop_prob: 0.0
  value_drop_prob: 0.1
  bffn_drop_prob: 0.1
  batch_size: 128
  lr: 0.001
  weight_decay: 0.001
  eta: 0.1
  epochs: 30
  optimizer: "nadamw" # "adamw", "nadamw", "adan", "lion", or "sophia"
  patience: 2
  num_workers: 2